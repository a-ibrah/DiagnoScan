{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ali2/Test/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Ali2/Test/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1520\n",
      "Epoch 2/10, Loss: 0.0729\n",
      "Epoch 3/10, Loss: 0.0463\n",
      "Epoch 4/10, Loss: 0.0402\n",
      "Epoch 5/10, Loss: 0.0319\n",
      "Epoch 6/10, Loss: 0.0156\n",
      "Epoch 7/10, Loss: 0.0254\n",
      "Epoch 8/10, Loss: 0.0254\n",
      "Epoch 9/10, Loss: 0.0178\n",
      "Epoch 10/10, Loss: 0.0129\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Paths\n",
    "data_dir = \"/Users/Ali2/Documents/LC25000_lung\"\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize like ImageNet\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = models.resnet18(pretrained=True)  # Use ResNet18 pretrained on ImageNet\n",
    "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))  # Adjust output layer for 3 classes\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"model1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Model 2\n",
    "\n",
    "- Uses 5-folds cross validation\n",
    "- Uses 5 epochs (instead of 10 like before) to save time and prevent over fitting\n",
    "- Uses early stopping to terminate training automatically when perofmance stops improving\n",
    "- Use a confusion matrix to understand class-wise performance (e.g., is the model struggling with one class?)\n",
    "- Augment the training dataset with techniques like random rotations, flips, or color jittering: revents overfitting when training on limited data\n",
    "- More messages to indicate how long the program will take to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with 5 folds, 5 epochs per fold.\n",
      "\n",
      "Fold 1/5\n",
      "Training on 12000 samples, validating on 3000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ali2/Test/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Ali2/Test/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5...\n",
      "    Training Loss: 0.2133\n",
      "    Validation Loss: 0.1768\n",
      "  Epoch 2/5...\n",
      "    Training Loss: 0.1270\n",
      "    Validation Loss: 0.1307\n",
      "  Epoch 3/5...\n",
      "    Training Loss: 0.0999\n",
      "    Validation Loss: 0.1134\n",
      "  Epoch 4/5...\n",
      "    Training Loss: 0.0829\n",
      "    Validation Loss: 0.0719\n",
      "  Epoch 5/5...\n",
      "    Training Loss: 0.0774\n",
      "    Validation Loss: 0.1499\n",
      "    Early stopping patience count: 1/3\n",
      "\n",
      "Fold 2/5\n",
      "Training on 12000 samples, validating on 3000 samples.\n",
      "  Epoch 1/5...\n",
      "    Training Loss: 0.2272\n",
      "    Validation Loss: 0.1062\n",
      "  Epoch 2/5...\n",
      "    Training Loss: 0.1329\n",
      "    Validation Loss: 0.0751\n",
      "  Epoch 3/5...\n",
      "    Training Loss: 0.0992\n",
      "    Validation Loss: 0.0923\n",
      "    Early stopping patience count: 1/3\n",
      "  Epoch 4/5...\n",
      "    Training Loss: 0.0900\n",
      "    Validation Loss: 0.0673\n",
      "  Epoch 5/5...\n",
      "    Training Loss: 0.0757\n",
      "    Validation Loss: 0.1823\n",
      "    Early stopping patience count: 1/3\n",
      "\n",
      "Fold 3/5\n",
      "Training on 12000 samples, validating on 3000 samples.\n",
      "  Epoch 1/5...\n",
      "    Training Loss: 0.2132\n",
      "    Validation Loss: 0.1451\n",
      "  Epoch 2/5...\n",
      "    Training Loss: 0.1414\n",
      "    Validation Loss: 0.1057\n",
      "  Epoch 3/5...\n",
      "    Training Loss: 0.1057\n",
      "    Validation Loss: 0.1423\n",
      "    Early stopping patience count: 1/3\n",
      "  Epoch 4/5...\n",
      "    Training Loss: 0.0929\n",
      "    Validation Loss: 0.1137\n",
      "    Early stopping patience count: 2/3\n",
      "  Epoch 5/5...\n",
      "    Training Loss: 0.0683\n",
      "    Validation Loss: 0.0395\n",
      "\n",
      "Fold 4/5\n",
      "Training on 12000 samples, validating on 3000 samples.\n",
      "  Epoch 1/5...\n",
      "    Training Loss: 0.2064\n",
      "    Validation Loss: 0.3006\n",
      "  Epoch 2/5...\n",
      "    Training Loss: 0.1302\n",
      "    Validation Loss: 0.1169\n",
      "  Epoch 3/5...\n",
      "    Training Loss: 0.1027\n",
      "    Validation Loss: 0.1145\n",
      "  Epoch 4/5...\n",
      "    Training Loss: 0.0827\n",
      "    Validation Loss: 0.0698\n",
      "  Epoch 5/5...\n",
      "    Training Loss: 0.0715\n",
      "    Validation Loss: 0.0952\n",
      "    Early stopping patience count: 1/3\n",
      "\n",
      "Fold 5/5\n",
      "Training on 12000 samples, validating on 3000 samples.\n",
      "  Epoch 1/5...\n",
      "    Training Loss: 0.2038\n",
      "    Validation Loss: 0.1472\n",
      "  Epoch 2/5...\n",
      "    Training Loss: 0.1303\n",
      "    Validation Loss: 0.1971\n",
      "    Early stopping patience count: 1/3\n",
      "  Epoch 3/5...\n",
      "    Training Loss: 0.0949\n",
      "    Validation Loss: 0.0675\n",
      "  Epoch 4/5...\n",
      "    Training Loss: 0.0834\n",
      "    Validation Loss: 0.0584\n",
      "  Epoch 5/5...\n",
      "    Training Loss: 0.0594\n",
      "    Validation Loss: 0.0697\n",
      "    Early stopping patience count: 1/3\n",
      "\n",
      "Best fold is Fold 3 with Validation Loss: 0.0395\n",
      "Best model saved at temp_best_model_fold_2.pth\n",
      "\n",
      "Evaluating the best fold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/gg5hxknn41gbnjhv7ltchw940000gq/T/ipykernel_60057/2083297201.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Best Fold:\n",
      "[[ 980    4   36]\n",
      " [   1 1025    0]\n",
      " [   4    0  950]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         adenocarcinomas       0.99      0.96      0.98      1020\n",
      "           benign_tissue       1.00      1.00      1.00      1026\n",
      "squamous_cell_carcinomas       0.96      1.00      0.98       954\n",
      "\n",
      "                accuracy                           0.98      3000\n",
      "               macro avg       0.98      0.99      0.98      3000\n",
      "            weighted avg       0.99      0.98      0.98      3000\n",
      "\n",
      "Total training time: 485.03 minutes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "data_dir = \"/Users/Ali2/Documents/LC25000_lung\"\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "K_FOLDS = 5\n",
    "PATIENCE = 3  # Early stopping patience\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "dataset_size = len(dataset)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Track the best fold\n",
    "best_fold_idx = -1\n",
    "best_fold_loss = float('inf')\n",
    "best_model_path = \"best_model.pth\"\n",
    "\n",
    "print(f\"Starting training with {K_FOLDS} folds, {EPOCHS} epochs per fold.\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(range(dataset_size))):\n",
    "    print(f\"\\nFold {fold + 1}/{K_FOLDS}\")\n",
    "    print(f\"Training on {len(train_idx)} samples, validating on {len(val_idx)} samples.\")\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Define model\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"  Epoch {epoch + 1}/{EPOCHS}...\")\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        print(f\"    Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"    Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save best model weights for this fold\n",
    "            torch.save(model.state_dict(), f'temp_best_model_fold_{fold}.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"    Early stopping patience count: {epochs_no_improve}/{PATIENCE}\")\n",
    "\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"  Early stopping triggered at epoch {epoch + 1}.\")\n",
    "            break\n",
    "\n",
    "    # Update the best fold if this one is better\n",
    "    if best_val_loss < best_fold_loss:\n",
    "        best_fold_loss = best_val_loss\n",
    "        best_fold_idx = fold\n",
    "        # Keep the best model path\n",
    "        best_model_path = f'temp_best_model_fold_{fold}.pth'\n",
    "\n",
    "print(f\"\\nBest fold is Fold {best_fold_idx + 1} with Validation Loss: {best_fold_loss:.4f}\")\n",
    "print(f\"Best model saved at {best_model_path}\")\n",
    "\n",
    "# Load and evaluate the best fold\n",
    "print(\"\\nEvaluating the best fold...\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Reuse validation set for the best fold\n",
    "val_idx = list(kf.split(range(dataset_size)))[best_fold_idx][1]\n",
    "val_subset = Subset(dataset, val_idx)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(f\"\\nConfusion Matrix for Best Fold:\\n{conf_matrix}\")\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
    "\n",
    "# Final results\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {(end_time - start_time) / 60:.2f} minutes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
